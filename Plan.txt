  Contest目标为cifar-10的检测，属于基础数据集，探索空间其实不大。目前业界最高精度为99%，可查询结果最高为98.5%。我们自己训练，\
考虑各种训练调参实验成本及trick的使用，预期目标精度可以定到98%。不考虑有人直接使用网上的checkpoint，这个精度预计基本属于最靠前的。\
同时，本次竞赛结果包括提交结果与线下评比两部分，所以我们的核心赛点不应该只是最高精度，而更应该针对于优化过程。
  由于cifar-10数据较小，其实对于很多较大的网络来说，训练精度都可以很轻易地到达100%，而valid精度无法提升更高，\
  这证明cifar-10的训练过程中，肯定是存在着过拟合或训练集与验证集的分布偏向的问题。如何减小训练过程中的过拟合现象，\
提高泛化能力，从而缩减train_acc与valid_acc的gap，应该作为我们的核心赛点。

##具体方案：
###1、	模型选择：采用NAS方式进行搜索（我们之前工作已经有搜索出很多网络，同时各论文中也给出了自己的搜索网络，可以直接测试，挑选一个结果最好的），与现有经典网络进行对比。
###2、	优化点设计（进行对比实验）：
####A、--auxiliary
####B、dropout/disout
####C、cutout/autoAugment
####D、Flood training  
